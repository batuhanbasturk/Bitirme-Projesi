{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  \n",
    "  \n",
    "# Load the dataset into a pandas DataFrame  \n",
    "df = pd.read_csv('../data/preprocessed/main-data.csv')  \n",
    "X = df[[\"item_count\",\"cold_item\",\"frozen_item\",\"scalable_item\"]]\n",
    "Y= pd.cut(df['collection_duration'], bins=[0, 3, 9, float('inf')], labels=[0,1,2])  \n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "length_Train = len(X_train)\n",
    "length_Test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train without standardising features\n",
      "--------------------------------------\n",
      "         item_count  cold_item  frozen_item  scalable_item\n",
      "749391            4          0            0              0\n",
      "1154737           8          4            1              0\n",
      "1292598           5          1            1              1\n",
      "1325600           4          0            0              0\n",
      "1189916           4          1            0              0\n",
      "...             ...        ...          ...            ...\n",
      "110268            5          0            0              0\n",
      "259178            8          0            3              0\n",
      "131932            9          1            0              0\n",
      "671155            5          4            0              0\n",
      "121958            7          2            0              3\n",
      "\n",
      "[1103845 rows x 4 columns]\n",
      "\n",
      "X_train standardising features\n",
      "--------------------------------------\n",
      "[[-0.63745957 -0.83692167 -0.46273673 -0.54547169]\n",
      " [ 0.36737328  2.35632221  1.10352607 -0.54547169]\n",
      " [-0.38625136 -0.0386107   1.10352607  0.04646439]\n",
      " ...\n",
      " [ 0.61858149 -0.0386107  -0.46273673 -0.54547169]\n",
      " [-0.38625136  2.35632221 -0.46273673 -0.54547169]\n",
      " [ 0.11616507  0.75970027 -0.46273673  1.23033655]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_standard = sc.transform(X_train)\n",
    "X_test_standard = sc.transform(X_test)\n",
    "\n",
    "print(\"X_train without standardising features\")\n",
    "print(\"--------------------------------------\")\n",
    "print(X_train)\n",
    "print(\"\")\n",
    "print(\"X_train standardising features\")\n",
    "print(\"--------------------------------------\")\n",
    "print(X_train_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 0.81\n",
      "XGBoost's precision score is: 0.72\n",
      "XGBoost's recall score is: 0.81\n",
      "XGBoost's f1 score is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "# Fit the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='multi:softmax',\n",
    "                    num_class=3,\n",
    "                    multi_strategy='multi_output_tree',\n",
    "                    subsample= 1.0, \n",
    "                    n_estimators= 200, \n",
    "                    min_child_weight= 5, \n",
    "                    max_depth= 3, \n",
    "                    learning_rate= 0.1, \n",
    "                    gamma= 0.2, \n",
    "                    colsample_bytree= 0.9,\n",
    "                    )\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = xgb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc_xgb = accuracy_score(Y_test, preds)\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "# Calculate precision\n",
    "precision_xgb = precision_score(Y_test, preds, average='weighted')\n",
    "print(\"XGBoost's precision score is: %3.2f\" % (precision_xgb))\n",
    "\n",
    "# Calculate recall\n",
    "recall_xgb = recall_score(Y_test, preds, average='weighted')\n",
    "print(\"XGBoost's recall score is: %3.2f\" % (recall_xgb))\n",
    "\n",
    "# Calculate f1 score\n",
    "f1_xgb = f1_score(Y_test, preds, average='weighted')\n",
    "print(\"XGBoost's f1 score is: %3.2f\" % (f1_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost's prediction accuracy is: 0.76\n",
      "Best XGBoost's precision score is: 0.68\n",
      "Best XGBoost's recall score is: 0.76\n",
      "Best XGBoost's f1 score is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "#xgb = XGBClassifier(objective='multi:softprob','subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 3,  'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.9)\n",
    "\n",
    "# Initialize GridSearchCV or RandomizedSearchCV\n",
    "# For GridSearchCV\n",
    "#grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy',n_jobs=-1)\n",
    "\n",
    "# For RandomizedSearchCV\n",
    "#grid_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy',n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV or RandomizedSearchCV\n",
    "#grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "#best_params = grid_search.best_params_\n",
    "#print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Use the best parameters to fit the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='multi:softprob',\n",
    "                    subsample= 1.0, \n",
    "                    n_estimators= 200, \n",
    "                    min_child_weight= 5, \n",
    "                    max_depth= 3, \n",
    "                    learning_rate= 0.1, \n",
    "                    gamma= 0.2, \n",
    "                    colsample_bytree= 0.9)\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_best = xgb.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics using the best model\n",
    "acc_xgb_best = accuracy_score(Y_test, preds_best)\n",
    "precision_xgb_best = precision_score(Y_test, preds_best, average='weighted')\n",
    "recall_xgb_best = recall_score(Y_test, preds_best, average='weighted')\n",
    "f1_xgb_best = f1_score(Y_test, preds_best, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Best XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb_best))\n",
    "print(\"Best XGBoost's precision score is: %3.2f\" % (precision_xgb_best))\n",
    "print(\"Best XGBoost's recall score is: %3.2f\" % (recall_xgb_best))\n",
    "print(\"Best XGBoost's f1 score is: %3.2f\" % (f1_xgb_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 84.05\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3696\n",
      "           1       0.86      0.97      0.91    226373\n",
      "           2       0.64      0.28      0.39     45893\n",
      "\n",
      "    accuracy                           0.84    275962\n",
      "   macro avg       0.50      0.42      0.43    275962\n",
      "weighted avg       0.81      0.84      0.81    275962\n",
      "\n",
      "Confusion Matrix:\n",
      "[[     0   3696      0]\n",
      " [     0 218969   7404]\n",
      " [     0  32917  12976]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Amet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Amet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100)\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "preds = xgb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_xgb = (preds == Y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, preds))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV  \n",
    "from scipy.stats import randint  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer  \n",
    "  \n",
    "# Define the parameter distributions to search  \n",
    "param_dist = {  \n",
    "    'n_estimators': randint(50, 150),  # Number of boosting stages  \n",
    "    'learning_rate': [0.01, 0.1, 0.5],  # Step size shrinkage used in update to prevent overfitting  \n",
    "    'max_depth': [3, 4, 5],  # Maximum depth of the individual estimators  \n",
    "}  \n",
    "  \n",
    "# Define the scoring metrics  \n",
    "scoring = {  \n",
    "    'accuracy': make_scorer(accuracy_score),  \n",
    "    'precision': make_scorer(precision_score),  \n",
    "    'recall': make_scorer(recall_score),  \n",
    "    'f1': make_scorer(f1_score)  \n",
    "}  \n",
    "  \n",
    "# Initialize RandomizedSearchCV  \n",
    "random_search = RandomizedSearchCV(estimator=xg, param_distributions=param_dist, n_iter=10, cv=5, scoring=scoring, refit='accuracy', random_state=10, n_jobs=-1)  \n",
    "  \n",
    "# Perform randomized search to find the best parameters  \n",
    "random_search.fit(X_train_standard, Y_train)  \n",
    "  \n",
    "# Get the best parameters  \n",
    "best_params = random_search.best_params_  \n",
    "print(\"Best Parameters:\", best_params)  \n",
    "  \n",
    "# Get the scores for all tried parameter combinations  \n",
    "results = random_search.cv_results_  \n",
    "tried_params = results['params']  \n",
    "accuracy_scores = results['mean_test_accuracy']  \n",
    "precision_scores = results['mean_test_precision']  \n",
    "recall_scores = results['mean_test_recall']  \n",
    "f1_scores = results['mean_test_f1']  \n",
    "  \n",
    "# Print the tried parameters and corresponding scores  \n",
    "print(\"Tried Parameters and Scores:\")  \n",
    "for params, acc, prec, rec, f1 in zip(tried_params, accuracy_scores, precision_scores, recall_scores, f1_scores):  \n",
    "    print(\"Parameters:\", params)  \n",
    "    print(\"Accuracy:\", acc)  \n",
    "    print(\"Precision:\", prec)  \n",
    "    print(\"Recall:\", rec)  \n",
    "    print(\"F1 Score:\", f1)  \n",
    "    print()  \n",
    "  \n",
    "# Train the model with the best parameters  \n",
    "best_xg = GradientBoostingClassifier(**best_params, random_state=10)  \n",
    "best_xg.fit(X_train_standard, Y_train)  \n",
    "  \n",
    "# Make predictions on the test set  \n",
    "Y_pred_xg = best_xg.predict(X_test_standard)  \n",
    "  \n",
    "# Evaluate the model  \n",
    "accuracy = accuracy_score(Y_test, Y_pred_xg)  \n",
    "precision = precision_score(Y_test, Y_pred_xg)  \n",
    "recall = recall_score(Y_test, Y_pred_xg)  \n",
    "f1 = f1_score(Y_test, Y_pred_xg)  \n",
    "  \n",
    "print(\"Evaluation Metrics on Test Set:\")  \n",
    "print(\"Accuracy: %.2f\" % accuracy)  \n",
    "print(\"Precision: %.2f\" % precision)  \n",
    "print(\"Recall: %.2f\" % recall)  \n",
    "print(\"F1 Score: %.2f\" % f1)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
